{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four major possibilities which may occur:\n",
    "Actual Fraud, Predicted Fraud: This is the win-win situation where your model was able to find and classify the fraud transaction\n",
    "\n",
    "Actual Legitimate, Predicted Legitimate: This is to classify normal behavior of majority of transactions\n",
    "\n",
    "Actual Legitimate, Predicted Fraud: This is a problem to the bank as the client may feel irritated, and maybe after a series of clarifications, the customer will be proved innocent. This may lead to wastage of resources but the bank will not incur a much of a loss.\n",
    "\n",
    "Actual Fraud, Predicted Legitimate: This is a huge problem as the fraud transaction is left undetected and the client may even file a legal suite against the bank that will lead to a huge loss incurred by the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can fairly conclude that a model with 99 percent classification accuracy after dropping out the fraud transactions may sound to be the best in textbook definitions, but does not hold true for a real-life scenario. Our model should be able to handle outliers, and be robust enough to predict them correctly even if there are chances of a false negative. So, what we see today in banks is something called Cost Sensitive Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simpler terms, we need to understand the negative aspect of an outlier and above all understand the cost/loss associated with once our algorithm doesn't do its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33419.0</td>\n",
       "      <td>-2.178201</td>\n",
       "      <td>-3.132187</td>\n",
       "      <td>1.315758</td>\n",
       "      <td>-0.129783</td>\n",
       "      <td>-2.736013</td>\n",
       "      <td>0.743459</td>\n",
       "      <td>-0.752718</td>\n",
       "      <td>-2.650826</td>\n",
       "      <td>-0.184284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.828762</td>\n",
       "      <td>-0.219136</td>\n",
       "      <td>-1.004913</td>\n",
       "      <td>0.788588</td>\n",
       "      <td>1.061994</td>\n",
       "      <td>-0.319407</td>\n",
       "      <td>-0.132313</td>\n",
       "      <td>0.333476</td>\n",
       "      <td>937.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151317.0</td>\n",
       "      <td>2.064423</td>\n",
       "      <td>0.185575</td>\n",
       "      <td>-1.684612</td>\n",
       "      <td>0.411066</td>\n",
       "      <td>0.479555</td>\n",
       "      <td>-0.797963</td>\n",
       "      <td>0.205544</td>\n",
       "      <td>-0.240568</td>\n",
       "      <td>0.415454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351331</td>\n",
       "      <td>-0.876025</td>\n",
       "      <td>0.343288</td>\n",
       "      <td>0.522189</td>\n",
       "      <td>-0.259568</td>\n",
       "      <td>0.173623</td>\n",
       "      <td>-0.056280</td>\n",
       "      <td>-0.029665</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132434.0</td>\n",
       "      <td>-0.547505</td>\n",
       "      <td>0.798072</td>\n",
       "      <td>-0.719939</td>\n",
       "      <td>-1.129561</td>\n",
       "      <td>0.925708</td>\n",
       "      <td>0.763338</td>\n",
       "      <td>0.231338</td>\n",
       "      <td>0.799204</td>\n",
       "      <td>-0.277812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366664</td>\n",
       "      <td>1.068933</td>\n",
       "      <td>-0.101523</td>\n",
       "      <td>-1.604148</td>\n",
       "      <td>-0.318277</td>\n",
       "      <td>0.838076</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>-0.015564</td>\n",
       "      <td>11.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81787.0</td>\n",
       "      <td>-0.945710</td>\n",
       "      <td>0.323579</td>\n",
       "      <td>0.595681</td>\n",
       "      <td>-1.288095</td>\n",
       "      <td>0.818906</td>\n",
       "      <td>-0.748491</td>\n",
       "      <td>0.890076</td>\n",
       "      <td>-0.130671</td>\n",
       "      <td>-0.471365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371528</td>\n",
       "      <td>-1.149510</td>\n",
       "      <td>0.217859</td>\n",
       "      <td>-0.507989</td>\n",
       "      <td>-0.026857</td>\n",
       "      <td>0.591496</td>\n",
       "      <td>-0.326179</td>\n",
       "      <td>-0.007543</td>\n",
       "      <td>24.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125062.0</td>\n",
       "      <td>1.898722</td>\n",
       "      <td>-0.321038</td>\n",
       "      <td>-1.771837</td>\n",
       "      <td>0.672408</td>\n",
       "      <td>0.115019</td>\n",
       "      <td>-1.267347</td>\n",
       "      <td>0.612810</td>\n",
       "      <td>-0.441070</td>\n",
       "      <td>0.450298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>-0.029094</td>\n",
       "      <td>-0.071333</td>\n",
       "      <td>0.179444</td>\n",
       "      <td>0.378225</td>\n",
       "      <td>-0.106042</td>\n",
       "      <td>-0.059506</td>\n",
       "      <td>104.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   33419.0 -2.178201 -3.132187  1.315758 -0.129783 -2.736013  0.743459   \n",
       "1  151317.0  2.064423  0.185575 -1.684612  0.411066  0.479555 -0.797963   \n",
       "2  132434.0 -0.547505  0.798072 -0.719939 -1.129561  0.925708  0.763338   \n",
       "3   81787.0 -0.945710  0.323579  0.595681 -1.288095  0.818906 -0.748491   \n",
       "4  125062.0  1.898722 -0.321038 -1.771837  0.672408  0.115019 -1.267347   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -0.752718 -2.650826 -0.184284  ... -0.828762 -0.219136 -1.004913  0.788588   \n",
       "1  0.205544 -0.240568  0.415454  ... -0.351331 -0.876025  0.343288  0.522189   \n",
       "2  0.231338  0.799204 -0.277812  ...  0.366664  1.068933 -0.101523 -1.604148   \n",
       "3  0.890076 -0.130671 -0.471365  ... -0.371528 -1.149510  0.217859 -0.507989   \n",
       "4  0.612810 -0.441070  0.450298  ...  0.015111  0.006269 -0.029094 -0.071333   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  1.061994 -0.319407 -0.132313  0.333476  937.75      0  \n",
       "1 -0.259568  0.173623 -0.056280 -0.029665    1.98      0  \n",
       "2 -0.318277  0.838076  0.012324 -0.015564   11.95      0  \n",
       "3 -0.026857  0.591496 -0.326179 -0.007543   24.98      0  \n",
       "4  0.179444  0.378225 -0.106042 -0.059506  104.36      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df_train = pd.read_csv('/Users/shivangeeacharya/Downloads/Data_Science_Project/creditcard_train.csv')\n",
    "df_test = pd.read_csv('/Users/shivangeeacharya/Downloads/Data_Science_Project/creditcard_test.csv')\n",
    "df = df_train\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    199000\n",
       "0    199000\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "resampled_X, resampled_Y = sm.fit_resample(df.drop('Class', axis=1), df['Class'])\n",
    "oversampled_df = pd.concat([pd.DataFrame(resampled_X), pd.DataFrame(resampled_Y)], axis=1)\n",
    "oversampled_df.columns = df.columns\n",
    "oversampled_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_X_df_test, resampled_Y_df_test = sm.fit_resample(df_test.drop('Class', axis=1), df_test['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(resampled_X, resampled_Y, train_size=0.8, random_state=0)\n",
    "X_train_df_test, X_test_df_test, y_train_df_test, y_test_df_test = train_test_split(resampled_X_df_test, resampled_Y_df_test, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     39996\n",
      "           1       0.97      0.95      0.96     39604\n",
      "\n",
      "    accuracy                           0.96     79600\n",
      "   macro avg       0.96      0.96      0.96     79600\n",
      "weighted avg       0.96      0.96      0.96     79600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Continue fitting the model and obtain predictions\n",
    "model = LogisticRegression()\n",
    "model.fit(resampled_X, resampled_Y)\n",
    "# Get model performance metrics\n",
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85443, 30)\n",
      "(85443,)\n"
     ]
    }
   ],
   "source": [
    "X_test_df_test, Y_test_df_test = df_test.drop('Class', axis=1), df_test['Class']\n",
    "print(X_test_df_test.shape)\n",
    "print(Y_test_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     85315\n",
      "           1       0.04      0.85      0.08       128\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.52      0.91      0.53     85443\n",
      "weighted avg       1.00      0.97      0.98     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(sampling_strategy='minority', random_state=7)\n",
    "resampled_X_df_test, resampled_Y_df_test = sm.fit_resample(X_test_df_test, Y_test_df_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "predicted_df_test = model.predict(X_test_df_test)\n",
    "print(classification_report(Y_test_df_test, predicted_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     85315\n",
      "           1       0.97      0.95      0.96     85315\n",
      "\n",
      "    accuracy                           0.96    170630\n",
      "   macro avg       0.96      0.96      0.96    170630\n",
      "weighted avg       0.96      0.96      0.96    170630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(resampled_X, resampled_Y)\n",
    "\n",
    "predicted_df_test_1 = model.predict(resampled_X_df_test)\n",
    "print(classification_report(resampled_Y_df_test, predicted_df_test_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Using the resampled training test and resampled testing set of the training dataset<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of tuples with classifier label and classifier object\n",
    "classifiers = {}\n",
    "classifiers.update({\"LDA\": LinearDiscriminantAnalysis()})\n",
    "classifiers.update({\"QDA\": QuadraticDiscriminantAnalysis()})\n",
    "classifiers.update({\"AdaBoost\": AdaBoostClassifier()})\n",
    "classifiers.update({\"Bagging\": BaggingClassifier()})\n",
    "classifiers.update({\"Extra Trees Ensemble\": ExtraTreesClassifier()})\n",
    "classifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})\n",
    "classifiers.update({\"Random Forest\": RandomForestClassifier()})\n",
    "classifiers.update({\"Ridge\": RidgeClassifier()})\n",
    "classifiers.update({\"SGD\": SGDClassifier()})\n",
    "classifiers.update({\"BNB\": BernoulliNB()})\n",
    "classifiers.update({\"GNB\": GaussianNB()})\n",
    "classifiers.update({\"KNN\": KNeighborsClassifier()})\n",
    "classifiers.update({\"MLP\": MLPClassifier()})\n",
    "classifiers.update({\"LSVC\": LinearSVC()})\n",
    "classifiers.update({\"NuSVC\": NuSVC()})\n",
    "classifiers.update({\"SVC\": SVC()})\n",
    "classifiers.update({\"DTC\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ETC\": ExtraTreeClassifier()})\n",
    "\n",
    "# Create dict of decision function labels\n",
    "DECISION_FUNCTIONS = {\"Ridge\", \"SGD\", \"LSVC\", \"NuSVC\", \"SVC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameter grid\n",
    "parameters = {}\n",
    "\n",
    "# Update dict with LDA\n",
    "parameters.update({\"LDA\": {\"classifier__solver\": [\"svd\"], \n",
    "                                         }})\n",
    "\n",
    "# Update dict with QDA\n",
    "parameters.update({\"QDA\": {\"classifier__reg_param\":[0.01*ii for ii in range(0, 101)], \n",
    "                                         }})\n",
    "# Update dict with AdaBoost\n",
    "parameters.update({\"AdaBoost\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 1.0]\n",
    "                                 }})\n",
    "\n",
    "# Update dict with Bagging\n",
    "parameters.update({\"Bagging\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__max_features\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                \"classifier__n_jobs\": [-1]\n",
    "                                }})\n",
    "\n",
    "# Update dict with Gradient Boosting\n",
    "parameters.update({\"Gradient Boosting\": { \n",
    "                                        \"classifier__learning_rate\":[0.15,0.1,0.05,0.01,0.005,0.001], \n",
    "                                        \"classifier__n_estimators\": [200],\n",
    "                                        \"classifier__max_depth\": [2,3,4,5,6],\n",
    "                                        \"classifier__min_samples_split\": [0.001, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__min_samples_leaf\": [0.001, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"classifier__subsample\": [1]\n",
    "                                         }})\n",
    "\n",
    "\n",
    "# Update dict with Extra Trees\n",
    "parameters.update({\"Extra Trees Ensemble\": { \n",
    "                                            \"classifier__n_estimators\": [200],\n",
    "                                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                            \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                            \"classifier__min_samples_split\": [0.001, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__min_samples_leaf\": [0.001, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                            \"classifier__n_jobs\": [-1]\n",
    "                                             }})\n",
    "\n",
    "\n",
    "# Update dict with Random Forest Parameters\n",
    "parameters.update({\"Random Forest\": { \n",
    "                                    \"classifier__n_estimators\": [200],\n",
    "                                    \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                    \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                    \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                    \"classifier__min_samples_split\": [0.001, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__min_samples_leaf\": [0.001, 0.01, 0.05, 0.10],\n",
    "                                    \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                    \"classifier__n_jobs\": [-1]\n",
    "                                     }})\n",
    "\n",
    "# Update dict with Ridge\n",
    "parameters.update({\"Ridge\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with SGD Classifier\n",
    "parameters.update({\"SGD\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0],\n",
    "                            \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with BernoulliNB Classifier\n",
    "parameters.update({\"BNB\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with GaussianNB Classifier\n",
    "parameters.update({\"GNB\": { \n",
    "                            \"classifier__var_smoothing\": [1e-9, 1e-8,1e-7, 1e-6, 1e-5]\n",
    "                             }})\n",
    "\n",
    "# Update dict with K Nearest Neighbors Classifier\n",
    "parameters.update({\"KNN\": { \n",
    "                            \"classifier__n_neighbors\": list(range(1,31)),\n",
    "                            \"classifier__p\": [1, 2, 3, 4, 5],\n",
    "                            \"classifier__leaf_size\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "# Update dict with MLPClassifier\n",
    "parameters.update({\"MLP\": { \n",
    "                            \"classifier__hidden_layer_sizes\": [(5), (10), (5,5), (10,10), (10,10,10)],\n",
    "                            \"classifier__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                            \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                            \"classifier__max_iter\": [100, 200, 300, 500],\n",
    "                            \"classifier__alpha\": list(10.0 ** -np.arange(5, 10)),\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"LSVC\": { \n",
    "                            \"classifier__penalty\": [\"l2\"],\n",
    "                            \"classifier__C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"NuSVC\": { \n",
    "                            \"classifier__nu\": [0.25, 0.50, 0.75],\n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__degree\": [1,2,3,4,5,6],\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"SVC\": { \n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__gamma\": [\"auto\"],\n",
    "                            \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                            \"classifier__degree\": [1, 2, 3, 4, 5, 6]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with Decision Tree Classifier\n",
    "parameters.update({\"DTC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n",
    "# Update dict with Extra Tree Classifier\n",
    "parameters.update({\"ETC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning LDA.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning QDA.\n",
      "Fitting 5 folds for each of 101 candidates, totalling 505 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 505 out of 505 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning AdaBoost.\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 24.4min\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Tune and evaluate classifiers\n",
    "for classifier_label, classifier in classifiers.items():\n",
    "    # Print message to user\n",
    "    print(f\"Now tuning {classifier_label}.\")\n",
    "    \n",
    "    # Scale features via Z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Define steps in pipeline\n",
    "    steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "      \n",
    "    # Define parameter grid\n",
    "    param_grid = parameters[classifier_label]\n",
    "    \n",
    "    # Initialize GridSearch object\n",
    "    gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"recall\")\n",
    "                      \n",
    "    # Fit gscv\n",
    "    gscv.fit(X_train, np.ravel(y_train))  \n",
    "    \n",
    "    # Get best parameters and score\n",
    "    best_params = gscv.best_params_\n",
    "    best_score = gscv.best_score_\n",
    "    \n",
    "    # Update classifier parameters and define new pipeline with tuned classifier\n",
    "    tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "    classifier.set_params(**tuned_params)\n",
    "            \n",
    "    # Make predictions\n",
    "    if classifier_label in DECISION_FUNCTIONS:\n",
    "        y_pred = gscv.decision_function(X_test_df_test)\n",
    "    else:\n",
    "        y_pred = gscv.predict_proba(X_test_df_test)[:,1]\n",
    "    \n",
    "    # Get AUC\n",
    "    auc = metrics.roc_auc_score(y_test_df_test, y_pred)\n",
    "    \n",
    "    # Get f1 score\n",
    "    y_pred = gscv.predict(X_test_df_test)\n",
    "    f1 = metrics.f1_score(y_test_df_test, y_pred)\n",
    "    \n",
    "    # Get recall score\n",
    "    recall = metrics.recall_score(y_test_df_test, y_pred)\n",
    "\n",
    "    # Get precision score\n",
    "    precision = metrics.precision_score(y_test_df_test, y_pred)\n",
    "    \n",
    "    # False Positive rate\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_df_test, y_pred).ravel()\n",
    "    fp_rate = (fp)/(fp + tn)\n",
    "\n",
    "    # Save results\n",
    "    result = {\"Classifier\": gscv,\n",
    "              \"Best Parameters\": best_params,\n",
    "              \"Training Recall Score\": best_score,\n",
    "              \"Test Recall Score\": recall,\n",
    "              \"Test Precision Score\": precision,\n",
    "              \"Test F1 Score\": f1,\n",
    "              \"False Positive Rate\": fp_rate,\n",
    "              \"Test AUC\": auc}\n",
    "    \n",
    "    results.update({classifier_label: result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Tune and evaluate classifiers\n",
    "for classifier_label, classifier in classifiers.items():\n",
    "    # Print message to user\n",
    "    print(f\"Now tuning {classifier_label}.\")\n",
    "    \n",
    "    # Scale features via Z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Define steps in pipeline\n",
    "    steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "      \n",
    "    # Define parameter grid\n",
    "    param_grid = parameters[classifier_label]\n",
    "    \n",
    "    # Initialize GridSearch object\n",
    "    gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"recall\")\n",
    "                      \n",
    "    # Fit gscv\n",
    "    gscv.fit(X_train, np.ravel(y_train))  \n",
    "    \n",
    "    # Get best parameters and score\n",
    "    best_params = gscv.best_params_\n",
    "    best_score = gscv.best_score_\n",
    "    \n",
    "    # Update classifier parameters and define new pipeline with tuned classifier\n",
    "    tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "    classifier.set_params(**tuned_params)\n",
    "            \n",
    "    # Make predictions\n",
    "    if classifier_label in DECISION_FUNCTIONS:\n",
    "        y_pred = gscv.decision_function(X_test_df_test)\n",
    "    else:\n",
    "        y_pred = gscv.predict_proba(X_test_df_test)[:,1]\n",
    "    \n",
    "    # Get AUC\n",
    "    auc = metrics.roc_auc_score(y_test_df_test, y_pred)\n",
    "    \n",
    "    # Get f1 score\n",
    "    y_pred = gscv.predict(X_test_df_test)\n",
    "    f1 = metrics.f1_score(y_test_df_test, y_pred)\n",
    "    \n",
    "    # Get recall score\n",
    "    recall = metrics.recall_score(y_test_df_test, y_pred)\n",
    "\n",
    "    # Get precision score\n",
    "    precision = metrics.precision_score(y_test_df_test, y_pred)\n",
    "    \n",
    "    # False Positive rate\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_df_test, y_pred).ravel()\n",
    "    fp_rate = (fp)/(fp + tn)\n",
    "\n",
    "    # Save results\n",
    "    result = {\"Classifier\": gscv,\n",
    "              \"Best Parameters\": best_params,\n",
    "              \"Training Recall Score\": best_score,\n",
    "              \"Test Recall Score\": recall,\n",
    "              \"Test Precision Score\": precision,\n",
    "              \"Test F1 Score\": f1,\n",
    "              \"False Positive Rate\": fp_rate,\n",
    "              \"Test AUC\": auc}\n",
    "    \n",
    "    results.update({classifier_label: result})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to show values on bar\n",
    "def show_values_on_bars(axs, h_v=\"v\", space=0.4):\n",
    "    def _show_on_single_plot(ax):\n",
    "        if h_v == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif h_v == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height()\n",
    "                value = int(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "        \n",
    "        \n",
    "# Recall scores plot\n",
    "recall_scores = {\n",
    "              \"Classifier\": [],\n",
    "              \"Recall Score\": [],\n",
    "              \"Precision Score\": [],\n",
    "              \"Difference\": []\n",
    "              }\n",
    "\n",
    "# Get recall scores into dictionary\n",
    "for classifier_label in results:  \n",
    "    recall_scores.update({\"Classifier\": [classifier_label] + recall_scores[\"Classifier\"],\n",
    "                       \"Recall Score\": [results[classifier_label][\"Test Recall Score\"]] + recall_scores[\"Recall Score\"]\n",
    "                       })\n",
    "\n",
    "# Dictionary to PandasDataFrame\n",
    "recall_scores = pd.DataFrame(recall_scores)\n",
    "\n",
    "# Sort dataframe\n",
    "recall_scores = recall_scores.sort_values(by = [\"Recall Score\"], ascending = False)\n",
    "\n",
    "# Convert decimals to percentages\n",
    "recall_scores[recall_scores.select_dtypes(include=['number']).columns] *= 100\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "# Colors\n",
    "palette = sns.color_palette(\"YlOrRd\", 20)[::-1]\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "g = sns.barplot(x=\"Recall Score\", y=\"Classifier\", palette = palette,\n",
    "            data = recall_scores)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Show values\n",
    "show_values_on_bars(g, h_v=\"h\", space=0.4)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"Recall Scores Bar Plot of Oversampled Data.png\", dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive rate plot\n",
    "fpr_scores = {\n",
    "              \"Classifier\": [],\n",
    "              \"Test Precision Score\": [],\n",
    "              }\n",
    "\n",
    "# Get fpr into dictionary\n",
    "for classifier_label in results:\n",
    "    fpr_scores.update({\"Classifier\": [classifier_label] + fpr_scores[\"Classifier\"],\n",
    "                       \"Test Precision Score\": [results[classifier_label][\"Test Precision Score\"]] + fpr_scores[\"Test Precision Score\"]\n",
    "                       })\n",
    "    \n",
    "\n",
    "# Dictionary to PandasDataFrame\n",
    "fpr_scores = pd.DataFrame(fpr_scores)\n",
    "\n",
    "# Sort dataframe\n",
    "fpr_scores = fpr_scores.sort_values(by = [\"Test Precision Score\"])\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "# Colors\n",
    "palette = sns.color_palette(\"YlGn\", 20)[::-1]\n",
    "\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "sns.barplot(x=\"Test Precision Score\", y=\"Classifier\", palette = palette,\n",
    "            data = fpr_scores)\n",
    "\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save Figure\n",
    "plt.savefig(\"Final Precision Score Bar Plot of Oversampled Data.png\", dpi = 1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recall scores into dictionary\n",
    "from currency_converter import CurrencyConverter\n",
    "c = CurrencyConverter()\n",
    "\n",
    "for classifier_label in results:\n",
    "    # Classifier\n",
    "    classifier = results[classifier_label][\"Classifier\"]\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    # Get the difference\n",
    "    difference = np.abs(114*fn - 5*fp)\n",
    "    pounds = c.convert(difference, 'EUR', 'GBP')\n",
    "\n",
    "    \n",
    "    print(f\"{classifier_label} difference is {difference} euros.\")\n",
    "    print(f\"{classifier_label} difference in pounds is {pounds} British pounds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "classifier = results[\"Extra Trees Ensemble\"][\"Classifier\"]\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "    \n",
    "# Get indices from test set\n",
    "test_index = y_test.index\n",
    "\n",
    "# Get indices of false positives and true positives in y_pred\n",
    "fp_tp_index = test_index[y_pred == 1] \n",
    "\n",
    "# Get rows test set that corresponds to false positives and true positive\n",
    "fp_tp = data_test.loc[fp_tp_index, :]\n",
    "fp_tp['Class'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set graph style\n",
    "sns.set(font_scale = 0.3)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4', 'axes.grid': False})\n",
    "\n",
    "# Define color palette\n",
    "palette = sns.color_palette(\"RdYlGn\", 10)\n",
    "palette = [palette[0], palette[-1]]\n",
    "\n",
    "# Make graph\n",
    "g = sns.pairplot(data = fp_tp, palette  = palette, \n",
    "                 plot_kws=dict(s=1, edgecolor= None, linewidth=0.5), hue = \"Class\")\n",
    "\n",
    "# Set figure size\n",
    "g.fig.set_size_inches(12,9)\n",
    "\n",
    "# Save figure\n",
    "g.savefig(\"FP TP Pair Plot of Oversampled Data.png\", dpi = 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scores1 = {\n",
    "              \"Classifier\": [],\n",
    "              \"Recall Score\": [],\n",
    "              \"Precision Score\": [],\n",
    "                \"AUC Score\": [],\n",
    "              }\n",
    "for classifier_label in results:  \n",
    "    recall_scores1.update({\"Classifier\": [classifier_label] + recall_scores1[\"Classifier\"],\n",
    "                       \"Recall Score\": [results[classifier_label][\"Test Recall Score\"]] + recall_scores1[\"Recall Score\"],\n",
    "                          \"Precision Score\": [results[classifier_label][\"Test Precision Score\"]] + recall_scores1[\"Precision Score\"],\n",
    "                           \"AUC Score\": [results[classifier_label][\"Test AUC\"]] + recall_scores1[\"AUC Score\"]\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to PandasDataFrame\n",
    "scores = pd.DataFrame(recall_scores1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set name of the classifiers as index labels\n",
    "scores.set_index('Classifier', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['Test Precision Score'] = fpr_scores['Test Precision Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "iplot({\n",
    "     'data':\n",
    "         [{'x': [0,1],\n",
    "           'y': scores['AUC Score'],\n",
    "           'name': col} for col in df.index[1:-1]],\n",
    "           'layout':{'title':'AUC Plot'}}, show_link=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
